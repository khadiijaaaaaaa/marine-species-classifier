{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# --- Environment Setup ---","metadata":{}},{"cell_type":"code","source":"!pip install -q gdown\n\nimport os\nimport json\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torchvision import models\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T08:24:44.526102Z","iopub.execute_input":"2025-05-19T08:24:44.526783Z","iopub.status.idle":"2025-05-19T08:24:59.887625Z","shell.execute_reply.started":"2025-05-19T08:24:44.526758Z","shell.execute_reply":"2025-05-19T08:24:59.886997Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# --- Download and Extract Data ---","metadata":{}},{"cell_type":"code","source":"import gdown\nurl = 'https://drive.google.com/uc?id=1ptdvy-EAT4IFtnvD1ZGDgRRhEigN1hyU'\noutput = 'fathomnet.zip'\ngdown.download(url, output, quiet=False)\n!unzip -q fathomnet.zip -d /kaggle/working/fathomnet_unzipped","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T08:24:59.888820Z","iopub.execute_input":"2025-05-19T08:24:59.889251Z","iopub.status.idle":"2025-05-19T08:25:27.462613Z","shell.execute_reply.started":"2025-05-19T08:24:59.889221Z","shell.execute_reply":"2025-05-19T08:25:27.461878Z"}},"outputs":[{"name":"stderr","text":"Downloading...\nFrom (original): https://drive.google.com/uc?id=1ptdvy-EAT4IFtnvD1ZGDgRRhEigN1hyU\nFrom (redirected): https://drive.google.com/uc?id=1ptdvy-EAT4IFtnvD1ZGDgRRhEigN1hyU&confirm=t&uuid=bbe3fd17-b4ce-4ec4-8b37-e448b3302054\nTo: /kaggle/working/fathomnet.zip\n100%|██████████| 1.25G/1.25G [00:11<00:00, 105MB/s] \n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import gdown\nurl = 'https://drive.google.com/uc?id=1eOtHFtawo1pmNzAomdvWEZkpZFoE-4xU'\noutput = 'full_taxonomy.json'\ngdown.download(url, output, quiet=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T08:25:35.104702Z","iopub.execute_input":"2025-05-19T08:25:35.106046Z","iopub.status.idle":"2025-05-19T08:25:39.092630Z","shell.execute_reply.started":"2025-05-19T08:25:35.106014Z","shell.execute_reply":"2025-05-19T08:25:39.091889Z"}},"outputs":[{"name":"stderr","text":"Downloading...\nFrom: https://drive.google.com/uc?id=1eOtHFtawo1pmNzAomdvWEZkpZFoE-4xU\nTo: /kaggle/working/full_taxonomy.json\n100%|██████████| 19.1k/19.1k [00:00<00:00, 19.8MB/s]\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'full_taxonomy.json'"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"# --- Paths ---","metadata":{}},{"cell_type":"code","source":"DATA_DIR = \"/kaggle/working/fathomnet_unzipped\"\nTRAIN_IMG_DIR = os.path.join(DATA_DIR, \"train_data/rois\")\nTEST_IMG_DIR = os.path.join(DATA_DIR, \"test_data/rois\")\ntrain_df = pd.read_csv(os.path.join(DATA_DIR, \"train_data/annotations.csv\"))\ntest_df = pd.read_csv(os.path.join(DATA_DIR, \"test_data/annotations.csv\"))\n\nprint(\"Train:\", len(train_df), \"Test:\", len(test_df))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T08:25:39.093661Z","iopub.execute_input":"2025-05-19T08:25:39.093890Z","iopub.status.idle":"2025-05-19T08:25:39.186467Z","shell.execute_reply.started":"2025-05-19T08:25:39.093847Z","shell.execute_reply":"2025-05-19T08:25:39.185748Z"}},"outputs":[{"name":"stdout","text":"Train: 23699 Test: 788\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# --- Load Taxonomy File ---","metadata":{}},{"cell_type":"code","source":"with open(\"/kaggle/working/full_taxonomy.json\") as f:\n    taxonomy = json.load(f)\n\n# Build label to best taxon and taxonomic depth dictionary\ntaxonomic_ranks = [\"kingdom\", \"phylum\", \"class\", \"order\", \"family\", \"genus\", \"species\"]\nlabel_to_best_taxon = {}\nlabel_to_depth_map = {}\n\nfor entry in taxonomy:\n    for i, rank in enumerate(taxonomic_ranks):\n        if entry[rank] != \"unknown\":\n            label_to_best_taxon[entry[\"label\"]] = entry[rank]\n            label_to_depth_map[entry[rank]] = i\n            break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T08:25:56.775248Z","iopub.execute_input":"2025-05-19T08:25:56.775539Z","iopub.status.idle":"2025-05-19T08:25:56.781579Z","shell.execute_reply.started":"2025-05-19T08:25:56.775517Z","shell.execute_reply":"2025-05-19T08:25:56.780825Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# --- Apply Taxonomy to Train Labels ---","metadata":{}},{"cell_type":"code","source":"train_df['label'] = train_df['label'].map(label_to_best_taxon)\ntrain_df['path'] = train_df['path'].apply(lambda x: os.path.basename(x))\ntest_df['path'] = test_df['path'].apply(lambda x: os.path.basename(x))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T08:26:01.568305Z","iopub.execute_input":"2025-05-19T08:26:01.568574Z","iopub.status.idle":"2025-05-19T08:26:01.597252Z","shell.execute_reply.started":"2025-05-19T08:26:01.568554Z","shell.execute_reply":"2025-05-19T08:26:01.596724Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"test_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T08:26:05.239064Z","iopub.execute_input":"2025-05-19T08:26:05.239625Z","iopub.status.idle":"2025-05-19T08:26:05.258252Z","shell.execute_reply.started":"2025-05-19T08:26:05.239605Z","shell.execute_reply":"2025-05-19T08:26:05.257671Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"      path  label\n0  1_1.png    NaN\n1  2_2.png    NaN\n2  2_3.png    NaN\n3  2_4.png    NaN\n4  2_5.png    NaN","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1_1.png</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2_2.png</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2_3.png</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2_4.png</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2_5.png</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"# --- Dataset Class ---","metadata":{}},{"cell_type":"markdown","source":"# --- Transforms ---","metadata":{}},{"cell_type":"code","source":"class OceanDataset(Dataset):\n    def __init__(self, df, img_dir, transform=None):\n        self.df = df.reset_index(drop=True)\n        self.img_dir = img_dir\n        self.transform = transform\n        self.label_to_idx = {label: i for i, label in enumerate(sorted(self.df['label'].unique()))}\n        self.idx_to_label = {i: label for label, i in self.label_to_idx.items()}\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, self.df.iloc[idx]['path'])\n        image = Image.open(img_path).convert(\"RGB\")\n        label = self.label_to_idx[self.df.iloc[idx]['label']]\n        if self.transform:\n            image = self.transform(image)\n        return image, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T08:26:15.460430Z","iopub.execute_input":"2025-05-19T08:26:15.461059Z","iopub.status.idle":"2025-05-19T08:26:15.466608Z","shell.execute_reply.started":"2025-05-19T08:26:15.461033Z","shell.execute_reply":"2025-05-19T08:26:15.465911Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T08:26:19.955608Z","iopub.execute_input":"2025-05-19T08:26:19.956285Z","iopub.status.idle":"2025-05-19T08:26:19.960192Z","shell.execute_reply.started":"2025-05-19T08:26:19.956261Z","shell.execute_reply":"2025-05-19T08:26:19.959513Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# --- Split Train/Validation ---","metadata":{}},{"cell_type":"code","source":"train_df, val_df = train_test_split(train_df, test_size=0.2, stratify=train_df['label'], random_state=42)\n\ntrain_dataset = OceanDataset(train_df, TRAIN_IMG_DIR, transform)\nval_dataset = OceanDataset(val_df, TRAIN_IMG_DIR, transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T08:26:24.348273Z","iopub.execute_input":"2025-05-19T08:26:24.348607Z","iopub.status.idle":"2025-05-19T08:26:24.391182Z","shell.execute_reply.started":"2025-05-19T08:26:24.348587Z","shell.execute_reply":"2025-05-19T08:26:24.390360Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# --- Model ---","metadata":{}},{"cell_type":"code","source":"num_classes = len(train_dataset.label_to_idx)\nmodel = models.resnet18(pretrained=True)\nmodel.fc = nn.Linear(model.fc.in_features, num_classes)\nmodel = model.cuda()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T08:26:27.815183Z","iopub.execute_input":"2025-05-19T08:26:27.815674Z","iopub.status.idle":"2025-05-19T08:26:28.679590Z","shell.execute_reply.started":"2025-05-19T08:26:27.815652Z","shell.execute_reply":"2025-05-19T08:26:28.678777Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 181MB/s]\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"# --- Taxonomic Distance Matrix ---","metadata":{}},{"cell_type":"code","source":"distance_matrix = np.zeros((num_classes, num_classes), dtype=np.float32)\nlabels = list(train_dataset.label_to_idx.keys())\n\nfor i, label_i in enumerate(labels):\n    for j, label_j in enumerate(labels):\n        depth_i = label_to_depth_map.get(label_i, 0)\n        depth_j = label_to_depth_map.get(label_j, 0)\n        distance_matrix[i, j] = abs(depth_i - depth_j) if label_i != label_j else 0.0\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T08:26:34.256122Z","iopub.execute_input":"2025-05-19T08:26:34.256577Z","iopub.status.idle":"2025-05-19T08:26:34.261221Z","shell.execute_reply.started":"2025-05-19T08:26:34.256548Z","shell.execute_reply":"2025-05-19T08:26:34.260478Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# --- Custom Hierarchical Loss ---","metadata":{}},{"cell_type":"code","source":"class TaxonomicLoss(nn.Module):\n    def __init__(self, distance_matrix):\n        super().__init__()\n        self.distance_matrix = torch.tensor(distance_matrix).cuda()\n\n    def forward(self, preds, targets):\n        probs = torch.softmax(preds, dim=1)\n        batch_loss = 0.0\n        for i in range(preds.size(0)):\n            dists = self.distance_matrix[targets[i]]  # Distance to true class\n            loss = torch.dot(probs[i], dists)\n            batch_loss += loss\n        return batch_loss / preds.size(0)\n\ncriterion = TaxonomicLoss(distance_matrix)\noptimizer = optim.Adam(model.parameters(), lr=1e-4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T08:26:38.634301Z","iopub.execute_input":"2025-05-19T08:26:38.634945Z","iopub.status.idle":"2025-05-19T08:26:38.641338Z","shell.execute_reply.started":"2025-05-19T08:26:38.634924Z","shell.execute_reply":"2025-05-19T08:26:38.640785Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# --- Training Setup ---","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T08:26:42.927325Z","iopub.execute_input":"2025-05-19T08:26:42.927893Z","iopub.status.idle":"2025-05-19T08:26:42.931965Z","shell.execute_reply.started":"2025-05-19T08:26:42.927853Z","shell.execute_reply":"2025-05-19T08:26:42.931153Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"# --- Training Loop ---","metadata":{}},{"cell_type":"code","source":"def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10):\n    for epoch in range(epochs):\n        model.train()\n        train_loss, train_correct = 0.0, 0\n        for images, labels in train_loader:\n            images, labels = images.cuda(), labels.cuda()\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item() * images.size(0)\n            _, preds = torch.max(outputs, 1)\n            train_correct += torch.sum(preds == labels)\n\n        model.eval()\n        val_loss, val_correct = 0.0, 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.cuda(), labels.cuda()\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item() * images.size(0)\n                _, preds = torch.max(outputs, 1)\n                val_correct += torch.sum(preds == labels)\n\n        print(f\"Epoch {epoch+1}: Train Loss: {train_loss/len(train_loader.dataset):.4f}, \"\n              f\"Train Acc: {train_correct/len(train_loader.dataset):.4f}, \"\n              f\"Val Loss: {val_loss/len(val_loader.dataset):.4f}, \"\n              f\"Val Acc: {val_correct/len(val_loader.dataset):.4f}\")\n\ntrain_model(model, train_loader, val_loader, criterion, optimizer, epochs=15)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T08:26:49.652307Z","iopub.execute_input":"2025-05-19T08:26:49.653021Z"}},"outputs":[{"name":"stdout","text":"Epoch 1: Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0000, Val Acc: 1.0000\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"# --- Inference on Test Set ---","metadata":{}},{"cell_type":"code","source":"test_dataset = OceanDataset(test_df, TEST_IMG_DIR, transform)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n\nmodel.eval()\npreds = []\nwith torch.no_grad():\n    for images, _ in test_loader:\n        images = images.cuda()\n        outputs = model(images)\n        _, predicted = torch.max(outputs, 1)\n        preds.extend([test_dataset.idx_to_label[i] for i in predicted.cpu().numpy()])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# --submission--","metadata":{}},{"cell_type":"code","source":"submission = pd.DataFrame({\n    'annotation_id': test_df['annotation_id'],\n    'concept_name': preds\n})\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}